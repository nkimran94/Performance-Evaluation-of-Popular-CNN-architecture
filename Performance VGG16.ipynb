{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":262,"status":"ok","timestamp":1612530656917,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"6VNo5H_h0cf_","outputId":"40dad05b-ef7e-45b6-92a8-1bad4f81edc3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount ('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":3620,"status":"ok","timestamp":1612530662042,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"miyFJ-fPhzG0","outputId":"8e6a1abd-2258-47c6-be6c-c275d0748b5f"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.1'"]},"execution_count":2,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["import tensorflow as tf\n","tf.__version__\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":176,"status":"ok","timestamp":1612530663690,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"0nMnV1KQ0L97"},"outputs":[],"source":["import keras\n","from keras.models import Model\n","from keras.layers import Dense\n","from keras import optimizers\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.preprocessing import image"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":214,"status":"ok","timestamp":1612530666049,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"xYyfOLRtir4M","outputId":"18ba8849-67ca-4c70-ed73-3145de8a0ed1"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'2.4.3'"]},"execution_count":4,"metadata":{"tags":[]},"output_type":"execute_result"}],"source":["keras.__version__"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":958,"status":"ok","timestamp":1612530678196,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"R9g3a4rVRpGq"},"outputs":[],"source":["rm -r \"/content/train\""]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":11559,"status":"ok","timestamp":1612530694076,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"pN6e80VyDkuc"},"outputs":[],"source":["!unzip -q \"/content/drive/My Drive/train.zip\""]},{"cell_type":"markdown","metadata":{"id":"CuHMabyxYAhs"},"source":["X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k9FrqtpDJDQN"},"outputs":[],"source":["!unzip -q \"/content/drive/My Drive/test1.zip\""]},{"cell_type":"markdown","metadata":{"id":"GaBjRV76MDEx"},"source":["X"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":401,"status":"ok","timestamp":1612524168909,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"LDzOmi6-7aaq"},"outputs":[],"source":["!mkdir -p train\r\n","!mkdir -p test1"]},{"cell_type":"markdown","metadata":{"id":"M45D2qPSYRln"},"source":["X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F0kkjjLlXoab"},"outputs":[],"source":["!cp -av -r \"/content/drive/MyDrive/My data/train\" \"/content/train\""]},{"cell_type":"markdown","metadata":{"id":"16FcJ6HyME-5"},"source":["X"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3EhQtd9aY7UJ"},"outputs":[],"source":["%cp -av -r \"/content/test1/\" \"/content/drive/My Drive/My data\""]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":176,"status":"ok","timestamp":1612530716689,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"ZT-A_Tdn3JW4"},"outputs":[],"source":["train_dir = '/content/train/'\n","test_dir = '/content/test1/'"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":540,"status":"ok","timestamp":1612530718371,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"Smiv3X42FcKt"},"outputs":[],"source":["import numpy as np \n","import pandas as pd \n","\n","import shutil\n","from tqdm import tqdm\n","\n","import os\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import matplotlib.pyplot as plt\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"NcE9LmbrXYkX"},"source":["###ALL IMAGES ARE CHANGED HERE "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":356967,"status":"ok","timestamp":1612531100383,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"YUQAC_mJ3mYC","outputId":"839d619f-93b5-40a7-d973-938db1ab4660"},"outputs":[{"name":"stdout","output_type":"stream","text":["25000\n"]}],"source":["from PIL import Image\r\n","import glob\r\n","#image_list = []\r\n","d=0\r\n","for filename in glob.glob(train_dir+'*.jpg'): #assuming jpg\r\n","    img = cv2.imread(filename)\r\n","    #You can modify the code here#\r\n","    dst = np.empty_like(img) #create empty array the size of the image\r\n","    noise = cv2.randn(dst, (0,0,0), (20,20,20)) #add random img noise\r\n","    pup_noise = cv2.addWeighted(img, 0.5, noise, 0.5, 50) \r\n","\r\n","    # Blurring function; kernel=15, sigma=auto\r\n","    pup_blur = cv2.GaussianBlur(pup_noise, (15, 15), 0)\r\n","    #Your modification ends here#\r\n","    cv2.imwrite(filename, pup_blur)\r\n","    d+=1\r\n","    #if(d\u003e1):\r\n","    #  break\r\n","print(d)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":210,"status":"ok","timestamp":1612531111069,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"qRlbMe2cFtAz"},"outputs":[],"source":["\n","if not os.path.exists(train_dir):\n","    os.mkdir(train_dir)\n","if not os.path.exists(train_dir+\"dog\"): \n","    os.mkdir(train_dir+\"dog\")\n","if not os.path.exists(train_dir+\"cat\"):\n","    os.mkdir(train_dir+\"cat\")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":197,"status":"ok","timestamp":1612531112538,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"20Ad-r0EGRgb"},"outputs":[],"source":["import shutil\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1285,"status":"ok","timestamp":1612531115903,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"yIjY3FDvGV9j","outputId":"37a44e4c-45b0-4f7f-d024-1d8e6895c573"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 25002/25002 [00:01\u003c00:00, 24340.53it/s]\n"]}],"source":["#moving the picture into two subfolder according to their names.\n","\n","for i in tqdm(os.listdir(train_dir)):\n","#     print(i)\n","    if i.split(\".\")[0] == \"dog\":\n","      if(os.path.isfile(os.path.join(train_dir,i))):\n","        shutil.move(os.path.join(train_dir,i),os.path.join(train_dir+\"dog/\",i))\n","    elif i.split(\".\")[0] == \"cat\":\n","      if(os.path.isfile(os.path.join(train_dir,i))):\n","        shutil.move(os.path.join(train_dir,i),os.path.join(train_dir+\"cat/\",i))"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":218,"status":"ok","timestamp":1612531126848,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"Op7nfNzwG7Uk"},"outputs":[],"source":["if not os.path.exists(test_dir):\n","    os.mkdir(test_dir)\n","if not os.path.exists(test_dir+\"dog\"):\n","    os.mkdir(test_dir+\"dog\")\n","if not os.path.exists(test_dir+\"cat\"):\n","    os.mkdir(test_dir+\"cat\")"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":552,"status":"ok","timestamp":1612531132273,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"oyB0Oa55HJwz","outputId":"f88bb099-5e83-4099-ba7f-9da05f6c5f4a"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3000/3000 [00:00\u003c00:00, 19448.51it/s]\n","100%|██████████| 3000/3000 [00:00\u003c00:00, 16923.02it/s]\n"]}],"source":["for i in tqdm(os.listdir(train_dir+\"dog\")[:3000]):\n","    shutil.move(os.path.join(train_dir+\"dog\",i),os.path.join(test_dir+\"dog\",i)) \n","for i in tqdm(os.listdir(train_dir+\"cat\")[:3000]):\n","    shutil.move(os.path.join(train_dir+\"cat\",i),os.path.join(test_dir+\"cat\",i)) "]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":827,"status":"ok","timestamp":1612531135238,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"9eFvFu2B0jv3","outputId":"81b05b4b-484f-4bd8-a445-6c8b3cdd7eea"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 19000 images belonging to 2 classes.\n","Found 7394 images belonging to 2 classes.\n"]}],"source":["trdata = ImageDataGenerator()\n","traindata = trdata.flow_from_directory(directory=train_dir,target_size=(224,224)) #chossing the folder not the files\n","tsdata = ImageDataGenerator()\n","testdata = tsdata.flow_from_directory(directory=test_dir, target_size=(224,224))"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":4507,"status":"ok","timestamp":1612531141780,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"-7Ar_zHg0mC2"},"outputs":[],"source":["from keras.applications.vgg16 import VGG16\n","vggmodel = VGG16(weights='imagenet', include_top=True)"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":183,"status":"ok","timestamp":1612531144231,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"KjdCbgGt0oUW","outputId":"4b673cf0-40fd-4488-c272-86fc5dafdbfc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"vgg16\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","predictions (Dense)          (None, 1000)              4097000   \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["vggmodel.summary()"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":194,"status":"ok","timestamp":1612531147715,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"3VsCJkYU0qmP","outputId":"f9f30be3-fa31-405f-f293-6d7d83a98689"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003ctensorflow.python.keras.engine.input_layer.InputLayer object at 0x7fa031346048\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02ef4c518\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02ef4cfd0\u003e\n","\u003ctensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa02eed2828\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02eed92b0\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02eede6d8\u003e\n","\u003ctensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa02eee4e80\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02eed9f98\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02cf80ac8\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02cf86e10\u003e\n","\u003ctensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa02cf86a58\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02eedefd0\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02eed2c50\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02eea9588\u003e\n","\u003ctensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa02cf8c630\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02cf93f60\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02cf97cf8\u003e\n","\u003ctensorflow.python.keras.layers.convolutional.Conv2D object at 0x7fa02cf97940\u003e\n","\u003ctensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7fa02cf9aef0\u003e\n"]}],"source":["for layers in (vggmodel.layers)[:19]:\n","    print(layers)\n","    layers.trainable = False"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":217,"status":"ok","timestamp":1612531150512,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"ilWeGcUx0sy2"},"outputs":[],"source":["X= vggmodel.layers[-2].output\n","predictions = Dense(2, activation=\"softmax\")(X)\n","model_final = Model(inputs = vggmodel.inputs, outputs = predictions)"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":180,"status":"ok","timestamp":1612531152699,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"Y1zeGCNI0u4I"},"outputs":[],"source":["model_final.compile(loss = \"categorical_crossentropy\", optimizer = optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":204,"status":"ok","timestamp":1612531154108,"user":{"displayName":"image outpainting","photoUrl":"","userId":"18165438701033004816"},"user_tz":300},"id":"CpTxt3f50xKG","outputId":"6c5a459a-6287-45fe-bb33-e1d70a2301b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n","_________________________________________________________________\n","block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n","_________________________________________________________________\n","block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n","_________________________________________________________________\n","block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n","_________________________________________________________________\n","block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n","_________________________________________________________________\n","block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n","_________________________________________________________________\n","block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n","_________________________________________________________________\n","block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n","_________________________________________________________________\n","block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n","_________________________________________________________________\n","block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n","_________________________________________________________________\n","block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n","_________________________________________________________________\n","block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n","_________________________________________________________________\n","block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n","_________________________________________________________________\n","block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n","_________________________________________________________________\n","block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n","_________________________________________________________________\n","flatten (Flatten)            (None, 25088)             0         \n","_________________________________________________________________\n","fc1 (Dense)                  (None, 4096)              102764544 \n","_________________________________________________________________\n","fc2 (Dense)                  (None, 4096)              16781312  \n","_________________________________________________________________\n","dense (Dense)                (None, 2)                 8194      \n","=================================================================\n","Total params: 134,268,738\n","Trainable params: 119,554,050\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]}],"source":["model_final.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"8R9JlZz90zb-"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/100\n","2/2 [==============================] - 55s 34s/step - loss: 1.2489 - accuracy: 0.5625 - val_loss: 0.9978 - val_accuracy: 0.5625\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 2/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.9552 - accuracy: 0.5104 - val_loss: 0.8151 - val_accuracy: 0.5312\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 3/100\n","2/2 [==============================] - 52s 34s/step - loss: 0.8640 - accuracy: 0.5729 - val_loss: 0.9139 - val_accuracy: 0.4688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 4/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.8718 - accuracy: 0.6562 - val_loss: 0.6278 - val_accuracy: 0.6875\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 5/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.7757 - accuracy: 0.6458 - val_loss: 0.6163 - val_accuracy: 0.7188\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 6/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.5462 - accuracy: 0.7292 - val_loss: 0.4941 - val_accuracy: 0.7500\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 7/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.5774 - accuracy: 0.6979 - val_loss: 0.4052 - val_accuracy: 0.8125\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 8/100\n","2/2 [==============================] - 61s 44s/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.2133 - val_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 9/100\n","2/2 [==============================] - 52s 34s/step - loss: 0.5934 - accuracy: 0.7396 - val_loss: 0.3365 - val_accuracy: 0.8125\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 10/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2979 - accuracy: 0.8854 - val_loss: 0.3267 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 11/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1911 - accuracy: 0.9375 - val_loss: 0.5996 - val_accuracy: 0.7812\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 12/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.3555 - accuracy: 0.9167 - val_loss: 0.2739 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 13/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.5372 - accuracy: 0.7604 - val_loss: 0.6078 - val_accuracy: 0.7188\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 14/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.4395 - accuracy: 0.8125 - val_loss: 0.3503 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 15/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2031 - accuracy: 0.9167 - val_loss: 0.2759 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 16/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.3519 - accuracy: 0.8333 - val_loss: 0.3526 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 17/100\n","2/2 [==============================] - 51s 33s/step - loss: 0.3167 - accuracy: 0.8229 - val_loss: 0.4618 - val_accuracy: 0.8125\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 18/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2241 - accuracy: 0.8958 - val_loss: 0.3607 - val_accuracy: 0.7812\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 19/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2931 - accuracy: 0.8750 - val_loss: 0.2330 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 20/100\n","2/2 [==============================] - 64s 47s/step - loss: 0.2559 - accuracy: 0.8958 - val_loss: 0.2876 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 21/100\n","2/2 [==============================] - 52s 34s/step - loss: 0.3761 - accuracy: 0.7917 - val_loss: 0.2428 - val_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 22/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1683 - accuracy: 0.9375 - val_loss: 0.2507 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 23/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2155 - accuracy: 0.9375 - val_loss: 0.1863 - val_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 24/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1797 - accuracy: 0.9479 - val_loss: 0.1826 - val_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 25/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.3301 - accuracy: 0.8958 - val_loss: 0.3395 - val_accuracy: 0.8438\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 26/100\n","2/2 [==============================] - 50s 34s/step - loss: 0.1508 - accuracy: 0.9479 - val_loss: 0.1465 - val_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 27/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.3286 - accuracy: 0.9167 - val_loss: 0.2270 - val_accuracy: 0.8125\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 28/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2331 - accuracy: 0.8646 - val_loss: 0.3317 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 29/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2786 - accuracy: 0.9062 - val_loss: 0.2055 - val_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 30/100\n","2/2 [==============================] - 50s 34s/step - loss: 0.1678 - accuracy: 0.9479 - val_loss: 0.4051 - val_accuracy: 0.8438\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 31/100\n","2/2 [==============================] - 50s 33s/step - loss: 0.3263 - accuracy: 0.9062 - val_loss: 0.3415 - val_accuracy: 0.8125\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 32/100\n","2/2 [==============================] - 51s 33s/step - loss: 0.3253 - accuracy: 0.8646 - val_loss: 0.1413 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 33/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1625 - accuracy: 0.9167 - val_loss: 0.1815 - val_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 34/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2394 - accuracy: 0.9062 - val_loss: 0.2834 - val_accuracy: 0.8438\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 35/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.3109 - accuracy: 0.8750 - val_loss: 0.3020 - val_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 36/100\n","2/2 [==============================] - 52s 35s/step - loss: 0.2646 - accuracy: 0.8646 - val_loss: 0.1098 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 37/100\n","2/2 [==============================] - 66s 49s/step - loss: 0.2482 - accuracy: 0.9271 - val_loss: 0.3602 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 38/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2749 - accuracy: 0.8750 - val_loss: 0.1336 - val_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 39/100\n","2/2 [==============================] - 52s 34s/step - loss: 0.1924 - accuracy: 0.8854 - val_loss: 0.1430 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 40/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1732 - accuracy: 0.9271 - val_loss: 0.1630 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 41/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1601 - accuracy: 0.9375 - val_loss: 0.3552 - val_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 42/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2283 - accuracy: 0.8958 - val_loss: 0.3063 - val_accuracy: 0.8438\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 43/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2300 - accuracy: 0.8646 - val_loss: 0.1221 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 44/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2009 - accuracy: 0.8854 - val_loss: 0.5275 - val_accuracy: 0.7500\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 45/100\n","2/2 [==============================] - 52s 35s/step - loss: 0.2541 - accuracy: 0.8958 - val_loss: 0.1232 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 46/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2225 - accuracy: 0.8854 - val_loss: 0.1071 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 47/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2011 - accuracy: 0.8854 - val_loss: 0.2633 - val_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 48/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2448 - accuracy: 0.9062 - val_loss: 0.1585 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 49/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1132 - accuracy: 0.9271 - val_loss: 0.5849 - val_accuracy: 0.7500\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 50/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2209 - accuracy: 0.9375 - val_loss: 0.2074 - val_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 51/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2558 - accuracy: 0.9062 - val_loss: 0.0819 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 52/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1125 - accuracy: 0.9479 - val_loss: 0.3666 - val_accuracy: 0.8438\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 53/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1866 - accuracy: 0.9062 - val_loss: 0.4953 - val_accuracy: 0.7812\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 54/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2283 - accuracy: 0.9271 - val_loss: 0.1154 - val_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 55/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2428 - accuracy: 0.8958 - val_loss: 0.2074 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 56/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2173 - accuracy: 0.8958 - val_loss: 0.1308 - val_accuracy: 0.9688\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 57/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1298 - accuracy: 0.9792 - val_loss: 0.1774 - val_accuracy: 0.9375\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 58/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.1634 - accuracy: 0.9479 - val_loss: 0.2354 - val_accuracy: 0.9062\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 59/100\n","2/2 [==============================] - 51s 34s/step - loss: 0.2928 - accuracy: 0.8750 - val_loss: 0.2113 - val_accuracy: 0.8750\n","WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","Epoch 00059: early stopping\n"]}],"source":["from keras.callbacks import ModelCheckpoint, EarlyStopping\n","checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=40, verbose=1, mode='auto')\n","model_final.fit_generator(generator= traindata, steps_per_epoch= 2, epochs= 100, validation_data= testdata, validation_steps=1, callbacks=[checkpoint,early])\n","model_final.save_weights(\"vgg16_1.h5\")     "]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMJxU2tFgTZQHTsH9p4jTq1","collapsed_sections":[],"name":"Performance VGG16.ipynb","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}